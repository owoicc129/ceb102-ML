{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression 線性回歸\n",
    "ref: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "- 糖尿病資料集 來源： (點開User Guide 有欄位介紹)\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "1. Samples total：442  (樣本數442)               \n",
    "2. Dimensionality：10  (維度10)\n",
    "3. Features：real, -.2 < x < .2  (數值已經過正規化 介於-0.2~0.2間)\n",
    "4. Targets：integer 25 - 346    (目標：找到介於25~346之間的整數)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ -26.2759041  -231.92697391  566.49859849  303.08631061 -709.86807128\n",
      "  428.67719627   82.12319677  165.60628133  729.33691844   42.58281733]\n",
      "Mean squared error: 3319.6925871395583\n",
      "Variance score: 0.31749491764735915\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#載入資料\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# 定義 X  (diabetes.data 是前10欄的資料)\n",
    "diabetes_X = diabetes.data \n",
    "# print(diabetes_X.shape)  \n",
    "\n",
    "# 定義 Y  (diabetes.target 是第11欄的資料)\n",
    "diabetes_y = diabetes.target\n",
    "#print(diabetes_y)\n",
    "\n",
    "# 把 X改成 只取第3欄BMI指數 來畫圖，因為畫圖只能畫出兩個維度(原本是10維度)\n",
    "# diabetes_X = diabetes.data[:, None, 3] # None 是加一個維度, 3是欄位\n",
    "# print(diabetes_X.shape)\n",
    "\n",
    "#分成 訓練資料9成 測試資料1成\n",
    "diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = train_test_split(diabetes_X, diabetes_y, test_size=0.1, random_state=1)\n",
    "\n",
    "# 原本應該還要有一步 資料正規化，但因為原本的資料就已經做過，所以此處不用\n",
    "\n",
    "# 建模\n",
    "model = linear_model.LinearRegression()  \n",
    "\n",
    "# 訓練模型 調參數 θ0~θ2\n",
    "model.fit(diabetes_X_train, diabetes_y_train) \n",
    "\n",
    "# 訓練完就可用 model.predict 把 X測試代入 得到預測結果\n",
    "diabetes_y_pred = model.predict(diabetes_X_test)\n",
    "\n",
    "# 係數 訓練出來的θ0~θn\n",
    "print('Coefficients:', model.coef_)\n",
    "\n",
    "# MSE 平均平方誤差 (越小越好)\n",
    "print(\"Mean squared error:\",(mean_squared_error(diabetes_y_test, diabetes_y_pred)))\n",
    "\n",
    "# R平方 (越接近1越好)\n",
    "print('Variance score:',r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "                                      \n",
    "# 畫圖呈現 (搭配第18行)\n",
    "# plt.scatter(diabetes_X_test, diabetes_y_test,  color='black') #畫散射點\n",
    "# plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3) #畫線\n",
    "\n",
    "# plt.xticks(())\n",
    "# plt.yticks(())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 線性回歸 練習\n",
    "- 房價資料集 來源： (共14個欄位,506筆資料)\n",
    "- https://www.kaggle.com/c/boston-housing\n",
    "1. 不是正規的csv檔案\n",
    "2. 最後一欄是 房價中位數\n",
    "3. 用前面所有欄未去預測房價中位數 比對最後一欄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-1.0687251   1.16543133  0.38751811  0.78964813 -2.01245202  2.52486535\n",
      "  0.07708128 -3.00698459  2.58839007 -1.92592811 -2.08542166  0.85453073\n",
      " -4.08566478]\n",
      "Mean squared error: 22.362210932709512\n",
      "Variance score: 0.6540351800657843\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df = pd.read_csv('./dataset/housing.csv', header=None, delim_whitespace=True)\n",
    "                                                       #指定是否將空格用作sep，sep預設逗號\n",
    "\n",
    "# 定義 X，移除索引13那欄 (要比對的資料=特徵)\n",
    "X = df.drop([13], axis=1) \n",
    "\n",
    "# 定義 y，索引13的那欄 (拿來被預測出來的值 比對的)\n",
    "y = df[13] \n",
    "\n",
    "# 分成 9成訓練 1成測試\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1) \n",
    "\n",
    "# 用 z-score normalization算平均值.標準差\n",
    "scaler = preprocessing.StandardScaler().fit(X_train) \n",
    "\n",
    "# 用平均值和標準差 對數據進行正規化\n",
    "X_train = scaler.transform(X_train) \n",
    "\n",
    "#建模\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "#訓練  調參數\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "#[重點]用 x_train的平均值.標準差 再對 x_test做正規化\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "#訓練完就可用 model.predict 把 X測試代入 得到預測結果\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print('Coefficients:',model.coef_)\n",
    "print(\"Mean squared error:\",mean_squared_error(y_test, y_pred))\n",
    "print('Variance score:',r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression 多項式回歸 (變高維度)\n",
    "* /ˌpɑ liˈnoʊ mi əl/\n",
    "* ref: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X is: (100, 1)\n",
      "[[2.62626263]\n",
      " [6.26262626]\n",
      " [9.19191919]\n",
      " [5.25252525]\n",
      " [6.16161616]]\n",
      "=============\n",
      "[[ 1.          2.62626263  6.89725538]\n",
      " [ 1.          6.26262626 39.22048771]\n",
      " [ 1.          9.19191919 84.49137843]\n",
      " [ 1.          5.25252525 27.58902153]\n",
      " [ 1.          6.16161616 37.96551372]]\n",
      "Coefficients: [[   0.         -349.28647657  916.46178128]]\n",
      "Mean squared error: 1307.6467148653887\n",
      "Variance score: 0.9951790483339933\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def f(x):\n",
    "    \"\"\" 2x的3次方 - 2x \"\"\"\n",
    "    return 2*x*x*x - 2 *x  \n",
    "\n",
    "\n",
    "# 隨機產生資料集 介在0~10 分成100均等分\n",
    "X = np.linspace(0, 10, 100)\n",
    "np.random.shuffle(X) #洗牌\n",
    "X = X.reshape(-1,1)\n",
    "y = f(X)\n",
    "print('shape of X is:',X.shape)\n",
    "\n",
    "# 只看前5筆資料\n",
    "print(X[:5])\n",
    "print('=============')\n",
    "\n",
    "#-------------重點----------------\n",
    "\n",
    "poly = PolynomialFeatures(degree=2).fit(X)  #degree=2 把 n設成二次方\n",
    "X_poly = poly.transform(X) \n",
    "\n",
    "# 看轉換後 前5筆，每筆顯示 0次方.1次方.2次方\n",
    "print(X_poly[:5])\n",
    "\n",
    "#----------以下跟 Linear Regression一樣--------------\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_poly,y,test_size=0.3,random_state=1) #random_state 種子值\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "model = linear_model.LinearRegression() \n",
    "model.fit(X_train, y_train)  \n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Coefficients:',model.coef_)\n",
    "print(\"Mean squared error:\",mean_squared_error(y_test, y_pred))\n",
    "print('Variance score:',r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多項式回歸 練習\n",
    "- 紅酒資料集 來源： (共12個欄位,4898筆資料)\n",
    "- https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "1. 最後一欄 是紅酒的品質分數 0~10\n",
    "2. 前面都是 紅酒的特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-2.20439093e-11 -3.32036477e+01 -3.46762494e+01 -1.98569253e+01\n",
      " -1.40652656e+01 -6.85273381e+01 -7.74114997e+01  1.00727869e+02\n",
      " -2.50880009e+01 -7.93478035e+01  4.63945174e+01 -6.70038809e+00\n",
      " -1.07912073e+00 -4.28103408e-01 -1.80118094e-01 -5.27741073e-01\n",
      " -9.30638006e-01 -6.23191815e-01  5.34638897e-01  3.69394013e+01\n",
      " -1.63849368e+00  6.25798078e-01  6.86240624e-02 -1.07543978e-01\n",
      "  3.25708843e-02 -6.49414077e-02  2.15989372e-01 -5.66509424e-02\n",
      "  3.43575308e-01  3.51401508e+01 -1.05497188e+00 -2.55960941e-01\n",
      "  8.98178254e-01 -3.09937110e-02  9.34787505e-02  8.98840857e-02\n",
      "  1.48808583e-01 -3.20881226e-02  2.21970228e+01 -3.13608092e+00\n",
      " -3.12173913e-01  1.11046257e+00 -1.59627758e-01 -2.03532456e-01\n",
      "  3.43111110e-02 -6.51049711e-04  1.79109779e+01 -2.69409190e+00\n",
      "  1.29726359e-02 -3.65247752e-01  6.44755908e-02 -5.20131174e-02\n",
      " -1.18159029e-01  6.92374227e+01 -5.56852862e-01  1.09112468e-01\n",
      "  5.56498217e-01 -1.63840021e-01 -3.70231215e-02  7.79292790e+01\n",
      " -5.47020463e-01 -4.70828794e-01  1.29740195e+00  8.93119391e-02\n",
      " -1.01689650e+02  1.28353602e+00  4.09945512e-01 -1.61154603e+00\n",
      "  2.10910693e+01  8.08256509e+01 -4.72908479e+01  4.26542501e+00\n",
      " -2.92688018e+00  1.05074947e+00  2.71306226e+00 -3.52447248e-01\n",
      "  7.49136902e-02 -1.16178316e-01]\n",
      "Mean squared error: 0.4308785588450095\n",
      "Variance score: 0.2920650928975035\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df = pd.read_csv('./dataset/winequality-red.csv')\n",
    "\n",
    "X = df.drop('quality',axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "poly = PolynomialFeatures(degree=2).fit(X)\n",
    "X = poly.transform(X)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1) #random_state 種子值\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Coefficients:',model.coef_)\n",
    "print(\"Mean squared error:\",mean_squared_error(y_test, y_pred))\n",
    "print('Variance score:',r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logistic Regression   羅吉斯回歸\n",
    "#### (雖然是回歸，但常用在分類)\n",
    "ref: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "- 鳶尾花資料集 來源： (User Guide 可以看欄位簡介)\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
    "1. Classes：3  (分3種花)\n",
    "2. Samples per class：50  (每一種類50筆)\n",
    "3. Samples total：150 (共150筆)\n",
    "4. Dimensionality：4 (維度4，每一筆特徵有4個：花萼長寬.花蕊長寬)\n",
    "5. 目標：用前面4欄的特性，去看應該是屬於哪一類別的花"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[[-1.0169518   0.93320063 -1.71063824 -1.57995617]\n",
      " [ 0.64186897 -0.48170874 -0.2674308  -0.708515  ]\n",
      " [ 0.37508284 -0.4514919   1.97806903  2.28847117]]\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 2 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
      " 0 1 2 2 0 1 2 1]\n",
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data  \n",
    "y = iris.target #類別 3種\n",
    "\n",
    "print(X.shape) \n",
    "print(y)  # 有三個種類 所以 0 1 2 \n",
    "                                              \n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "\n",
    "# 用z-score normalization 算平均值.標準差\n",
    "scaler = preprocessing.StandardScaler().fit(X_train) \n",
    "\n",
    "# 用平均值和標準差 對數據進行正規化\n",
    "X_train = scaler.transform(X_train) \n",
    "\n",
    "#建模\n",
    "model=LogisticRegression()\n",
    "\n",
    "#訓練 調參數\n",
    "model.fit(X_train,y_train)  \n",
    "\n",
    "#[重點]用 x_train的平均值.標準差 再對 x_test做正規化\n",
    "X_test_nor = scaler.transform(X_test)  #nor = normalization 正規化\n",
    "\n",
    "#訓練完就可用 model.predict 把 X測試代入 得到預測結果\n",
    "y_pred = model.predict(X_test_nor) \n",
    "\n",
    "#算準確度\n",
    "accuracy = model.score(X_test_nor, y_test)\n",
    "\n",
    "print(model.coef_) \n",
    "print(y_pred) \n",
    "print(accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 羅吉斯回歸 練習\n",
    "- Pima印第安人資料集 來源： (共9個欄位,769筆資料)\n",
    "- https://www.kaggle.com/uciml/pima-indians-diabetes-database/data\n",
    "1. 最後一欄 是否得糖尿病 (是或否 兩個類別 0 or 1)\n",
    "2. 前面都是 病人的特徵 懷孕情況(pregnant)、體內胰島素含量(insulin)、BMI值(bmi)、年齡(age)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1]\n",
      "0.7056277056277056\n",
      "[[0.24527177 0.23789336 0.69148497 0.39595607]]\n",
      "[-0.78491863]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "\n",
    "pima = pd.read_csv('./dataset/pima-indians-diabetes.csv')\n",
    "\n",
    "#用'pregnant','insulin','bmi', 'age' 4個變數預測'label'(是否發病)\n",
    "df=pima[['pregnant', 'insulin', 'bmi', 'age', 'label']]\n",
    "\n",
    "X=df[['pregnant', 'insulin', 'bmi', 'age']]\n",
    "y=df['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1) \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "X_test_nor = scaler.transform(X_test)  #nor = normalization 正規化\n",
    "\n",
    "y_pred = model.predict(X_test_nor)\n",
    "accuracy = model.score(X_test_nor, y_test)\n",
    "\n",
    "print(y_pred)\n",
    "print(accuracy)\n",
    "print(model.coef_)\n",
    "print(model.intercept_ ) # 截距"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
