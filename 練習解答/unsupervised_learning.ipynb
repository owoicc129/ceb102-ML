{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data and Shape\n",
      "(3000, 2)\n",
      "centroids: [[ 69.92418447 -10.11964119]\n",
      " [ 40.68362784  59.71589274]\n",
      " [  9.4780459   10.686052  ]]\n",
      "prediction on each data: [2 2 2 ..., 0 0 0]\n",
      "prediction on data point (12.0, 14.0): [2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Importing the dataset\n",
    "data = pd.read_csv('./dataset/xclara.csv')\n",
    "print(\"Input Data and Shape\")\n",
    "print(data.shape)\n",
    "\n",
    "# Getting the values and plotting it\n",
    "f1 = data['V1'].values\n",
    "f2 = data['V2'].values\n",
    "X = np.array(list(zip(f1, f2)))\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans = kmeans.fit(X)\n",
    "labels = kmeans.predict(X)\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "print('centroids: {}'.format(centroids))\n",
    "print('prediction on each data: {}'.format(labels))\n",
    "\n",
    "labels = kmeans.predict(np.array([[12.0,14.0]]))\n",
    "print('prediction on data point (12.0, 14.0): {}'.format(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data and Shape\n",
      "     0    1    2    3\n",
      "0  5.1  3.5  1.4  0.2\n",
      "1  4.9  3.0  1.4  0.2\n",
      "2  4.7  3.2  1.3  0.2\n",
      "3  4.6  3.1  1.5  0.2\n",
      "4  5.0  3.6  1.4  0.2\n",
      "number of clusters: 3\n",
      "cluster on X [ 0  0  0  0  0 -1  0  0  0  0  0  0  0  0 -1 -1 -1  0 -1  0 -1  0 -1  0  0\n",
      "  0  0  0  0  0  0 -1 -1 -1  0  0 -1  0  0  0  0 -1  0  0 -1  0  0  0  0  0\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1  2 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1  1  1  1 -1 -1 -1 -1 -1  1  1 -1 -1  1 -1  1  1  1 -1 -1  1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1  2  2 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  2 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Importing the dataset\n",
    "df = pd.read_csv('./dataset/iris.csv', header=None)\n",
    "df = df.drop([4], axis=1)\n",
    "print(\"Input Data and Shape\")\n",
    "print(df.head())\n",
    "\n",
    "X = np.array(df)\n",
    "\n",
    "db = DBSCAN(eps=0.3, min_samples=5).fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print('number of clusters: {}'.format(n_clusters))\n",
    "print('cluster on X {}'.format(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data and Shape\n",
      "     0    1    2    3\n",
      "0  5.1  3.5  1.4  0.2\n",
      "1  4.9  3.0  1.4  0.2\n",
      "2  4.7  3.2  1.3  0.2\n",
      "3  4.6  3.1  1.5  0.2\n",
      "4  5.0  3.6  1.4  0.2\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 1 2\n",
      " 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import mixture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./dataset/iris.csv', header=None)\n",
    "df = df.drop([4], axis=1)\n",
    "print(\"Input Data and Shape\")\n",
    "print(df.head())\n",
    "\n",
    "X = np.array(df)\n",
    "\n",
    "gmm = mixture.GaussianMixture(n_components=3).fit(X)\n",
    "X_pred = gmm.predict(X)\n",
    "\n",
    "print(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
